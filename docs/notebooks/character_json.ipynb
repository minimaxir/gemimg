{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ed702a4",
   "metadata": {},
   "source": [
    "# Generating a character using a detailed description of the character\n",
    "\n",
    "Due to Gemini 2.5 Image Flash's long context window (relative to models such as Flux Pro/Kontext), you can put a massive amount of data in the prompt. Additionally, due to the more modern text encoder and multimodal training, the model is more receptive to stuctured data such as JSON, and in testing it can adhere to _all_ fields, including highly-nuanced ones.\n",
    "\n",
    "_**Ed. Note**: The character JSON used in this post was AI generated as a part of a very rough proof-of-concept for a separate project. It is far from optimized, but is more-than-enough to demonstrate the effectiveness of JSON inputs._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27803e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gemimg import GemImg\n",
    "import orjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec758344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemImg(model='gemini-2.5-flash-image-preview')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = GemImg()\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49bfbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'name\\': \"Athena \\'Code Weaver\\' Papadakis\", \\'gender\\': \\'female\\', \\'ethnicity\\': \\'Greek\\', \\'age\\': 28, \\'bac'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../files/character_json.json\", \"r\") as f:\n",
    "    char_json = orjson.loads(f.read())\n",
    "\n",
    "str(char_json)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70feeccb",
   "metadata": {},
   "source": [
    "While the full JSON is too large to include in this notebook, the relevant part is at the end of the JSON, which if included in the generation shows the prompt is not truncated:\n",
    "\n",
    "```json\n",
    "  \"equipment\": [\n",
    "    \"Custom-built ultrabook with an illuminated Greek keyboard\",\n",
    "    \"Set of miniature lockpicking tools disguised as hairpins\",\n",
    "    \"Several encrypted USB drives, each labeled with a different Greek deity's symbol\",\n",
    "    \"A small, portable, solar-powered charger resembling a traditional Greek worry bead string\"\n",
    "  ]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35570e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U8e9aIO9EP7gz7IPpObKgAc.png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate an image of the following character. The character is standing, and their entire body is clearly and completely visible in the image. The image is hyperrealistic, and is taken with a DSLR for a professional Vanity Fair profile of the character. Do not include any logos or watermarks. The lighting should be neutral, professional, and not overdone.\n",
    "\n",
    "The generated image MUST include ALL of the specified attributes about the character.\n",
    "---\n",
    "{orjson.dumps(char_json, option=orjson.OPT_INDENT_2).decode(\"utf-8\")}\n",
    "\"\"\"\n",
    "\n",
    "gen = g.generate(prompt)\n",
    "gen.image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f01558",
   "metadata": {},
   "source": [
    "![](gens/U8e9aIO9EP7gz7IPpObKgAc@0.5x.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a815d",
   "metadata": {},
   "source": [
    "The generation using this JSON is surprisingly stable even at `temperature=1.0`, retaining roughly the same character design across generations.\n",
    "\n",
    "![](gens/hacker@0.5x.webp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61a6487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(prompt_tokens=1073, completion_tokens=1290)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e49644",
   "metadata": {},
   "source": [
    "The input was indeed a lot of tokens.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemimg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
